{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82c60965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPLETE ML PIPELINE ===\n",
      "Numerical features: 27\n",
      "Top numerical features by correlation: ['TotalWorkingYears', 'JobLevel', 'YearsInCurrentRole', 'MonthlyIncome', 'Age', 'YearsWithCurrManager', 'StockOptionLevel', 'YearsAtCompany', 'JobInvolvement', 'JobSatisfaction']\n",
      "Important categorical features: ['OverTime', 'BusinessTravel', 'Department', 'JobRole']\n",
      "Final feature set (14): ['TotalWorkingYears', 'JobLevel', 'YearsInCurrentRole', 'MonthlyIncome', 'Age', 'YearsWithCurrManager', 'StockOptionLevel', 'YearsAtCompany', 'JobInvolvement', 'JobSatisfaction', 'OverTime', 'BusinessTravel', 'Department', 'JobRole']\n",
      "Data shape: (1470, 14)\n",
      "Attrition distribution: {0: 1233, 1: 237}\n",
      "\n",
      "=== HANDLING CLASS IMBALANCE ===\n",
      "After SMOTE - Class distribution: {1: 1233, 0: 1233}\n",
      "\n",
      "=== MODEL TRAINING & CROSS-VALIDATION ===\n",
      "Logistic Regression: F1 = 0.748 (+/- 0.037)\n",
      "Random Forest: F1 = 0.918 (+/- 0.012)\n",
      "\n",
      "ðŸŽ¯ BEST MODEL: Random Forest\n",
      "\n",
      "=== COMPREHENSIVE EVALUATION ===\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92       250\n",
      "           1       0.93      0.90      0.91       244\n",
      "\n",
      "    accuracy                           0.91       494\n",
      "   macro avg       0.92      0.91      0.91       494\n",
      "weighted avg       0.92      0.91      0.91       494\n",
      "\n",
      "ROC-AUC Score: 0.965\n",
      "\n",
      "ðŸŽ¯ FEATURE IMPORTANCE:\n",
      "                 feature  coefficient\n",
      "6       StockOptionLevel     0.147308\n",
      "4                    Age     0.085211\n",
      "3          MonthlyIncome     0.083357\n",
      "9        JobSatisfaction     0.082791\n",
      "10              OverTime     0.082346\n",
      "7         YearsAtCompany     0.078549\n",
      "1               JobLevel     0.075912\n",
      "5   YearsWithCurrManager     0.073082\n",
      "0      TotalWorkingYears     0.073018\n",
      "2     YearsInCurrentRole     0.054925\n",
      "ðŸ’¾ COMPLETE ML PIPELINE SAVED!\n",
      "âœ… ALL ML PROCEDURES COMPLETED:\n",
      "   - Feature selection & engineering\n",
      "   - Feature scaling\n",
      "   - Class imbalance handling (SMOTE)\n",
      "   - Cross-validation\n",
      "   - Multiple evaluation metrics\n",
      "   - Model interpretation\n"
     ]
    }
   ],
   "source": [
    "# notebooks/4_complete_ml_pipeline.ipynb - FIXED VERSION\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../data/employee_attrition.csv')\n",
    "df['Attrition'] = df['Attrition'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "print(\"=== COMPLETE ML PIPELINE ===\")\n",
    "\n",
    "# 1. SELECT ONLY NUMERICAL FEATURES FOR CORRELATION\n",
    "numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"Numerical features: {len(numerical_features)}\")\n",
    "\n",
    "# Calculate correlation with attrition using only numerical features\n",
    "correlation_with_attrition = df[numerical_features].corr()['Attrition'].abs().sort_values(ascending=False)\n",
    "top_numerical_features = correlation_with_attrition[1:11].index.tolist()  # Top 10 numerical features\n",
    "print(\"Top numerical features by correlation:\", top_numerical_features)\n",
    "\n",
    "# 2. ADD IMPORTANT CATEGORICAL FEATURES (from our previous analysis)\n",
    "important_categorical = ['OverTime', 'BusinessTravel', 'Department', 'JobRole']\n",
    "print(\"Important categorical features:\", important_categorical)\n",
    "\n",
    "# 3. COMBINE FEATURES\n",
    "top_features = top_numerical_features + important_categorical\n",
    "print(f\"Final feature set ({len(top_features)}): {top_features}\")\n",
    "\n",
    "# 4. PREPARE DATA\n",
    "X = df[top_features].copy()\n",
    "y = df['Attrition']\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for col in important_categorical:\n",
    "    if col in X.columns:\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# 5. SCALE FEATURES\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"Data shape: {X_scaled.shape}\")\n",
    "print(f\"Attrition distribution: {pd.Series(y).value_counts().to_dict()}\")\n",
    "\n",
    "# 6. HANDLE CLASS IMBALANCE WITH SMOTE\n",
    "print(\"\\n=== HANDLING CLASS IMBALANCE ===\")\n",
    "smote = SMOTE(random_state=42)\n",
    "X_balanced, y_balanced = smote.fit_resample(X_scaled, y)\n",
    "print(f\"After SMOTE - Class distribution: {pd.Series(y_balanced).value_counts().to_dict()}\")\n",
    "\n",
    "# 7. TRAIN-TEST SPLIT\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
    "\n",
    "# 8. MODEL TRAINING WITH CROSS-VALIDATION\n",
    "print(\"\\n=== MODEL TRAINING & CROSS-VALIDATION ===\")\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "cv_results = {}\n",
    "for name, model in models.items():\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='f1')\n",
    "    cv_results[name] = {\n",
    "        'mean_f1': cv_scores.mean(),\n",
    "        'std_f1': cv_scores.std()\n",
    "    }\n",
    "    print(f\"{name}: F1 = {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})\")\n",
    "\n",
    "# 9. TRAIN BEST MODEL ON FULL TRAINING SET\n",
    "best_model_name = max(cv_results, key=lambda x: cv_results[x]['mean_f1'])\n",
    "print(f\"\\nðŸŽ¯ BEST MODEL: {best_model_name}\")\n",
    "\n",
    "best_model = models[best_model_name]\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# 10. COMPREHENSIVE EVALUATION\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n=== COMPREHENSIVE EVALUATION ===\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_proba):.3f}\")\n",
    "\n",
    "# 11. FEATURE IMPORTANCE\n",
    "print(\"\\nðŸŽ¯ FEATURE IMPORTANCE:\")\n",
    "if best_model_name == 'Logistic Regression':\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': top_features,\n",
    "        'coefficient': best_model.coef_[0],\n",
    "        'abs_impact': np.abs(best_model.coef_[0])\n",
    "    }).sort_values('abs_impact', ascending=False)\n",
    "else:\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': top_features,\n",
    "        'coefficient': best_model.feature_importances_\n",
    "    }).sort_values('coefficient', ascending=False)\n",
    "\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# 12. SAVE COMPLETE PIPELINE\n",
    "import pickle\n",
    "with open('../models/final_model.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'model': best_model,\n",
    "        'scaler': scaler,\n",
    "        'feature_names': top_features,\n",
    "        'label_encoders': label_encoders,\n",
    "        'performance': {\n",
    "            'roc_auc': roc_auc_score(y_test, y_pred_proba),\n",
    "            'cv_f1': cv_results[best_model_name]['mean_f1']\n",
    "        }\n",
    "    }, f)\n",
    "\n",
    "print(\"ðŸ’¾ COMPLETE ML PIPELINE SAVED!\")\n",
    "print(\"âœ… ALL ML PROCEDURES COMPLETED:\")\n",
    "print(\"   - Feature selection & engineering\")\n",
    "print(\"   - Feature scaling\")\n",
    "print(\"   - Class imbalance handling (SMOTE)\")\n",
    "print(\"   - Cross-validation\")\n",
    "print(\"   - Multiple evaluation metrics\")\n",
    "print(\"   - Model interpretation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914e042c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
