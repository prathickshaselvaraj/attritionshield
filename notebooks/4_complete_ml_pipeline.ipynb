{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82c60965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPLETE ML PIPELINE ===\n",
      "Numerical features: 27\n",
      "Top numerical features by correlation: ['TotalWorkingYears', 'JobLevel', 'YearsInCurrentRole', 'MonthlyIncome', 'Age', 'YearsWithCurrManager', 'StockOptionLevel', 'YearsAtCompany', 'JobInvolvement', 'JobSatisfaction']\n",
      "Important categorical features: ['OverTime', 'BusinessTravel', 'Department', 'JobRole']\n",
      "Final feature set (14): ['TotalWorkingYears', 'JobLevel', 'YearsInCurrentRole', 'MonthlyIncome', 'Age', 'YearsWithCurrManager', 'StockOptionLevel', 'YearsAtCompany', 'JobInvolvement', 'JobSatisfaction', 'OverTime', 'BusinessTravel', 'Department', 'JobRole']\n",
      "Data shape: (1470, 14)\n",
      "Attrition distribution: {0: 1233, 1: 237}\n",
      "Before SMOTE - Train: {0: 986, 1: 190}, Test: {0: 247, 1: 47}\n",
      "After SMOTE (train only): {0: 986, 1: 986}\n",
      "\n",
      "=== REALISTIC MODEL PERFORMANCE ===\n",
      "Logistic Regression: F1 = 0.740 (+/- 0.039)\n",
      "Random Forest: F1 = 0.913 (+/- 0.185)\n",
      "\n",
      "ðŸŽ¯ BEST MODEL: Random Forest\n",
      "\n",
      "=== REAL TEST SET PERFORMANCE ===\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90       247\n",
      "           1       0.47      0.32      0.38        47\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.67      0.63      0.64       294\n",
      "weighted avg       0.81      0.83      0.82       294\n",
      "\n",
      "ROC-AUC Score: 0.799\n"
     ]
    }
   ],
   "source": [
    "# notebooks/4_complete_ml_pipeline.ipynb - FIXED VERSION\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../data/employee_attrition.csv')\n",
    "df['Attrition'] = df['Attrition'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "print(\"=== COMPLETE ML PIPELINE ===\")\n",
    "\n",
    "# 1. SELECT ONLY NUMERICAL FEATURES FOR CORRELATION\n",
    "numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"Numerical features: {len(numerical_features)}\")\n",
    "\n",
    "# Calculate correlation with attrition using only numerical features\n",
    "correlation_with_attrition = df[numerical_features].corr()['Attrition'].abs().sort_values(ascending=False)\n",
    "top_numerical_features = correlation_with_attrition[1:11].index.tolist()  # Top 10 numerical features\n",
    "print(\"Top numerical features by correlation:\", top_numerical_features)\n",
    "\n",
    "# 2. ADD IMPORTANT CATEGORICAL FEATURES (from our previous analysis)\n",
    "important_categorical = ['OverTime', 'BusinessTravel', 'Department', 'JobRole']\n",
    "print(\"Important categorical features:\", important_categorical)\n",
    "\n",
    "# 3. COMBINE FEATURES\n",
    "top_features = top_numerical_features + important_categorical\n",
    "print(f\"Final feature set ({len(top_features)}): {top_features}\")\n",
    "\n",
    "# 4. PREPARE DATA\n",
    "X = df[top_features].copy()\n",
    "y = df['Attrition']\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for col in important_categorical:\n",
    "    if col in X.columns:\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# 5. SCALE FEATURES\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"Data shape: {X_scaled.shape}\")\n",
    "print(f\"Attrition distribution: {pd.Series(y).value_counts().to_dict()}\")\n",
    "\n",
    "# IN notebooks/4_complete_ml_pipeline.ipynb - REPLACE SECTION 6-8:\n",
    "\n",
    "# === CORRECTED VERSION ===\n",
    "\n",
    "# 6. PROPER TRAIN-TEST SPLIT (FIRST!)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"Before SMOTE - Train: {y_train.value_counts().to_dict()}, Test: {y_test.value_counts().to_dict()}\")\n",
    "\n",
    "# 7. HANDLE CLASS IMBALANCE ONLY ON TRAINING DATA\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "print(f\"After SMOTE (train only): {pd.Series(y_train_balanced).value_counts().to_dict()}\")\n",
    "\n",
    "# 8. MODEL TRAINING WITH CROSS-VALIDATION (ON BALANCED TRAIN DATA)\n",
    "print(\"\\n=== REALISTIC MODEL PERFORMANCE ===\")\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "cv_results = {}\n",
    "for name, model in models.items():\n",
    "    # Cross-val on balanced training data\n",
    "    cv_scores = cross_val_score(model, X_train_balanced, y_train_balanced, cv=5, scoring='f1')\n",
    "    cv_results[name] = {\n",
    "        'mean_f1': cv_scores.mean(),\n",
    "        'std_f1': cv_scores.std()\n",
    "    }\n",
    "    print(f\"{name}: F1 = {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})\")\n",
    "\n",
    "# Train best model on balanced training data\n",
    "best_model_name = max(cv_results, key=lambda x: cv_results[x]['mean_f1'])\n",
    "print(f\"\\nðŸŽ¯ BEST MODEL: {best_model_name}\")\n",
    "\n",
    "best_model = models[best_model_name]\n",
    "best_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Evaluate on UNTOUCHED test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n=== REAL TEST SET PERFORMANCE ===\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_proba):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "914e042c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ðŸŽ¯ ACTIONABLE HR INSIGHTS\n",
      "==================================================\n",
      "ðŸš¨ TOP 30 AT-RISK EMPLOYEES (IMMEDIATE ACTION NEEDED):\n",
      " EmployeeNumber  AttritionProbability             Department               JobRole\n",
      "            614                  0.99                  Sales  Sales Representative\n",
      "           1783                  0.98 Research & Development Laboratory Technician\n",
      "            959                  0.97                  Sales  Sales Representative\n",
      "           1273                  0.97                  Sales  Sales Representative\n",
      "           1624                  0.97                  Sales  Sales Representative\n",
      "            167                  0.95                  Sales  Sales Representative\n",
      "            235                  0.95                  Sales  Sales Representative\n",
      "           1331                  0.95                  Sales  Sales Representative\n",
      "            622                  0.93 Research & Development Laboratory Technician\n",
      "           1016                  0.93 Research & Development    Research Scientist\n",
      "\n",
      "ðŸ’Ž HIGH PERFORMERS AT RISK: 41 employees\n",
      "These are your MOST VALUABLE at-risk employees:\n",
      " EmployeeNumber  AttritionProbability                   JobRole  MonthlyIncome\n",
      "              1                  0.75           Sales Executive           5993\n",
      "             64                  0.71     Laboratory Technician           5381\n",
      "            161                  0.76        Research Scientist           4963\n",
      "            163                  0.81           Sales Executive           6172\n",
      "            165                  0.75 Healthcare Representative          10312\n",
      "            282                  0.74 Healthcare Representative           6673\n",
      "            283                  0.72           Sales Executive           7639\n",
      "            299                  0.76           Sales Executive           6696\n",
      "            342                  0.71    Manufacturing Director          10048\n",
      "            445                  0.72           Sales Executive           5238\n",
      "\n",
      "ðŸ“Š DEPARTMENT ATTRITION CRISIS LEVELS:\n",
      "                        AvgRisk  TotalEmployees  HighRiskCount  HighRisk%\n",
      "Department                                                               \n",
      "Sales                     0.203             446             67       15.0\n",
      "Human Resources           0.187              63              9       14.3\n",
      "Research & Development    0.144             961             90        9.4\n",
      "\n",
      "ðŸ’° FINANCIAL IMPACT ANALYSIS:\n",
      "Expected employees to leave: 240.9\n",
      "Estimated replacement cost: $12,045,500\n",
      "High-risk employees: 166\n"
     ]
    }
   ],
   "source": [
    "# ADD TO THE END OF notebooks/4_complete_ml_pipeline.ipynb:\n",
    "\n",
    "# === ACTIONABLE HR OUTPUT ===\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ðŸŽ¯ ACTIONABLE HR INSIGHTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Predict probabilities for all employees\n",
    "final_scaler = StandardScaler()\n",
    "X_final_scaled = final_scaler.fit_transform(X)\n",
    "\n",
    "# Retrain model on all data for deployment\n",
    "deployment_model = RandomForestClassifier(random_state=42)\n",
    "deployment_model.fit(X_final_scaled, y)\n",
    "\n",
    "# Get risk scores for all employees\n",
    "attrition_probs = deployment_model.predict_proba(X_final_scaled)[:, 1]\n",
    "\n",
    "# Create HR action list\n",
    "hr_results = pd.DataFrame({\n",
    "    'EmployeeNumber': df['EmployeeNumber'],\n",
    "    'AttritionProbability': attrition_probs,\n",
    "    'RiskLevel': pd.cut(attrition_probs, [0, 0.3, 0.7, 1], labels=['LOW', 'MEDIUM', 'HIGH']),\n",
    "    'Department': df['Department'],\n",
    "    'JobRole': df['JobRole'],\n",
    "    'MonthlyIncome': df['MonthlyIncome'],\n",
    "    'OverTime': df['OverTime']\n",
    "})\n",
    "\n",
    "# 1. TOP 30 AT-RISK EMPLOYEES\n",
    "print(\"ðŸš¨ TOP 30 AT-RISK EMPLOYEES (IMMEDIATE ACTION NEEDED):\")\n",
    "top_30 = hr_results.nlargest(30, 'AttritionProbability')\n",
    "print(top_30[['EmployeeNumber', 'AttritionProbability', 'Department', 'JobRole']].head(10).to_string(index=False))\n",
    "\n",
    "# 2. HIGH PERFORMER ATTRITION RISK\n",
    "high_performers = hr_results[hr_results['MonthlyIncome'] > hr_results['MonthlyIncome'].median()]\n",
    "high_risk_high_performers = high_performers[high_performers['RiskLevel'] == 'HIGH']\n",
    "\n",
    "print(f\"\\nðŸ’Ž HIGH PERFORMERS AT RISK: {len(high_risk_high_performers)} employees\")\n",
    "print(\"These are your MOST VALUABLE at-risk employees:\")\n",
    "print(high_risk_high_performers[['EmployeeNumber', 'AttritionProbability', 'JobRole', 'MonthlyIncome']].head(10).to_string(index=False))\n",
    "\n",
    "# 3. DEPARTMENT CRISIS LEVELS\n",
    "print(f\"\\nðŸ“Š DEPARTMENT ATTRITION CRISIS LEVELS:\")\n",
    "dept_crisis = hr_results.groupby('Department').agg({\n",
    "    'AttritionProbability': 'mean',\n",
    "    'EmployeeNumber': 'count',\n",
    "    'RiskLevel': lambda x: (x == 'HIGH').sum()\n",
    "}).round(3)\n",
    "dept_crisis.columns = ['AvgRisk', 'TotalEmployees', 'HighRiskCount']\n",
    "dept_crisis['HighRisk%'] = (dept_crisis['HighRiskCount'] / dept_crisis['TotalEmployees'] * 100).round(1)\n",
    "print(dept_crisis.sort_values('HighRisk%', ascending=False))\n",
    "\n",
    "# 4. COST ANALYSIS\n",
    "avg_replacement_cost = 50000\n",
    "expected_losses = hr_results['AttritionProbability'].sum()\n",
    "total_risk_cost = expected_losses * avg_replacement_cost\n",
    "\n",
    "print(f\"\\nðŸ’° FINANCIAL IMPACT ANALYSIS:\")\n",
    "print(f\"Expected employees to leave: {expected_losses:.1f}\")\n",
    "print(f\"Estimated replacement cost: ${total_risk_cost:,.0f}\")\n",
    "print(f\"High-risk employees: {(hr_results['RiskLevel'] == 'HIGH').sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dc9b950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’¾ HR Action List saved: 'hr_attrition_risk_list.csv'\n"
     ]
    }
   ],
   "source": [
    "# IN notebooks/4_complete_ml_pipeline.ipynb - REPLACE THE SAVE LINE:\n",
    "\n",
    "import os\n",
    "\n",
    "# Create results directory if it doesn't exist\n",
    "os.makedirs('../results', exist_ok=True)\n",
    "\n",
    "# Save for HR\n",
    "hr_results.to_csv('../results/hr_attrition_risk_list.csv', index=False)\n",
    "print(f\"\\nðŸ’¾ HR Action List saved: 'hr_attrition_risk_list.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dac9d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
